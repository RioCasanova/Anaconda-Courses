{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c1565b",
   "metadata": {},
   "source": [
    "# Dates and Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e07fa",
   "metadata": {},
   "source": [
    "Being able to handle dates and times, particularly for time series applications, is a critical part of data-cleaning. It is easy to let subtle bugs creep in due to parsing dates and times incorrectly or not accounting for timezones. On rare occasion, you may encounter datasets coming from a system that bravely uses custom time types, like 27-hour clocks (yes, this happened to me!). The point is, working with dates and times can be messy so we will learn some practical strategies here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de517a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a52eac",
   "metadata": {},
   "source": [
    "We are going to load a dataframe from Github that contains 5 columns of dates and times, all representing the same value but in 5 different formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed09ed46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORD_ID</th>\n",
       "      <th>ORDER_DATE1</th>\n",
       "      <th>ORDER_DATE2</th>\n",
       "      <th>ORDER_DATE_TM1</th>\n",
       "      <th>ORDER_DATE_TM2</th>\n",
       "      <th>ORDER_DATE_TM3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>1/22/22</td>\n",
       "      <td>1/22/22 16:08</td>\n",
       "      <td>22-Jan-22 4:08 PM</td>\n",
       "      <td>Sat January 22, 2022 16:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>9/25/22</td>\n",
       "      <td>9/25/22 20:16</td>\n",
       "      <td>22-Sep-25 8:16 PM</td>\n",
       "      <td>Sun September 25, 2022 20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>7/31/22</td>\n",
       "      <td>7/31/22 0:32</td>\n",
       "      <td>22-Jul-31 12:32 AM</td>\n",
       "      <td>Sun July 31, 2022 0:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>7/20/22</td>\n",
       "      <td>7/20/22 11:57</td>\n",
       "      <td>22-Jul-20 11:57 AM</td>\n",
       "      <td>Wed July 20, 2022 11:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>4/26/22</td>\n",
       "      <td>4/26/22 0:48</td>\n",
       "      <td>22-Apr-26 12:48 AM</td>\n",
       "      <td>Tue April 26, 2022 0:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>1186</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>9/27/22</td>\n",
       "      <td>9/27/22 5:37</td>\n",
       "      <td>22-Sep-27 5:37 AM</td>\n",
       "      <td>Tue September 27, 2022 5:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>1187</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>6/18/22</td>\n",
       "      <td>6/18/22 1:31</td>\n",
       "      <td>22-Jun-18 1:31 AM</td>\n",
       "      <td>Sat June 18, 2022 1:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>1188</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>8/2/22</td>\n",
       "      <td>8/2/22 14:54</td>\n",
       "      <td>22-Aug-02 2:54 PM</td>\n",
       "      <td>Tue August 2, 2022 14:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>1189</td>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>12/11/22</td>\n",
       "      <td>12/11/22 12:48</td>\n",
       "      <td>22-Dec-11 12:48 PM</td>\n",
       "      <td>Sun December 11, 2022 12:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>1190</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>10/18/22</td>\n",
       "      <td>10/18/22 17:51</td>\n",
       "      <td>22-Oct-18 5:51 PM</td>\n",
       "      <td>Tue October 18, 2022 17:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RECORD_ID ORDER_DATE1 ORDER_DATE2  ORDER_DATE_TM1      ORDER_DATE_TM2  \\\n",
       "0             1  2022-01-22     1/22/22   1/22/22 16:08   22-Jan-22 4:08 PM   \n",
       "1             2  2022-09-25     9/25/22   9/25/22 20:16   22-Sep-25 8:16 PM   \n",
       "2             3  2022-07-31     7/31/22    7/31/22 0:32  22-Jul-31 12:32 AM   \n",
       "3             4  2022-07-20     7/20/22   7/20/22 11:57  22-Jul-20 11:57 AM   \n",
       "4             5  2022-04-26     4/26/22    4/26/22 0:48  22-Apr-26 12:48 AM   \n",
       "...         ...         ...         ...             ...                 ...   \n",
       "1185       1186  2022-09-27     9/27/22    9/27/22 5:37   22-Sep-27 5:37 AM   \n",
       "1186       1187  2022-06-18     6/18/22    6/18/22 1:31   22-Jun-18 1:31 AM   \n",
       "1187       1188  2022-08-02      8/2/22    8/2/22 14:54   22-Aug-02 2:54 PM   \n",
       "1188       1189  2022-12-11    12/11/22  12/11/22 12:48  22-Dec-11 12:48 PM   \n",
       "1189       1190  2022-10-18    10/18/22  10/18/22 17:51   22-Oct-18 5:51 PM   \n",
       "\n",
       "                    ORDER_DATE_TM3  \n",
       "0       Sat January 22, 2022 16:08  \n",
       "1     Sun September 25, 2022 20:16  \n",
       "2           Sun July 31, 2022 0:32  \n",
       "3          Wed July 20, 2022 11:57  \n",
       "4          Tue April 26, 2022 0:48  \n",
       "...                            ...  \n",
       "1185   Tue September 27, 2022 5:37  \n",
       "1186        Sat June 18, 2022 1:31  \n",
       "1187      Tue August 2, 2022 14:54  \n",
       "1188   Sun December 11, 2022 12:48  \n",
       "1189    Tue October 18, 2022 17:51  \n",
       "\n",
       "[1190 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/thomasnield/machine-learning-demo-data/master/timeseries/datetime_formatting.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c200dc6",
   "metadata": {},
   "source": [
    "Let's extract one of the columns and look at its datatypes. Noteice that it is a `dtype` of `object`, not a `datetime64` as we would want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4486f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1/22/22 16:08\n",
       "1        9/25/22 20:16\n",
       "2         7/31/22 0:32\n",
       "3        7/20/22 11:57\n",
       "4         4/26/22 0:48\n",
       "             ...      \n",
       "1185      9/27/22 5:37\n",
       "1186      6/18/22 1:31\n",
       "1187      8/2/22 14:54\n",
       "1188    12/11/22 12:48\n",
       "1189    10/18/22 17:51\n",
       "Name: ORDER_DATE_TM1, Length: 1190, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ORDER_DATE_TM1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162ad45",
   "metadata": {},
   "source": [
    "## Implicit Datetime Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb2bc1",
   "metadata": {},
   "source": [
    "If you want to do any useful calendar or time-based logic on these values, you will have to convert them to a different data type. One way to do this is to call Pandas' `to_datetime()` function on that column. Pandas will then do its best to parse the date for that series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac15c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_col = pd.to_datetime(df['ORDER_DATE_TM1'])\n",
    "parsed_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f96e0",
   "metadata": {},
   "source": [
    "We can use calendar-based logic to extract properties, like the day of week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_col.dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe832c",
   "metadata": {},
   "source": [
    "If you already know which columns you want to format as dates/times beforehand, you can pass the `parse_dates` parameter to the `read_csv()` function with a list of column names to expect dates/times form. Let's parse all the dates using this approach and analyze the result. For brevity, let's only look at the first three results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b73a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = pd.read_csv(url, \n",
    "            parse_dates=['ORDER_DATE1','ORDER_DATE2','ORDER_DATE_TM1','ORDER_DATE_TM2','ORDER_DATE_TM3'])\n",
    "\n",
    "df_parsed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9b3da",
   "metadata": {},
   "source": [
    "Are there any errors? As a matter of fact, the `ORDER_DATE_TM2` was parsed almost completely in error! For example, the second record really has values representing a datetime of `2022-09-25 20:16:00` but the `ORDER_DATE_TM2` was wrongly parsed as `2025-09-22 20:16:00`! What happened? \n",
    "\n",
    "Well let's look at the original value. As a matter of fact, let's sample the first three records and analyze what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659fc251",
   "metadata": {},
   "source": [
    "What seems to be happening with `ORDER_DATE_TM2` is it is confusing the day and month. Conventionally one might expect a format like `22-Sep-25 8:16 PM` to have the day `22` to be leading, and this is what Pandas assumed. However, a sadistic developer decided to arbitrate their own convention and record the year in that place instead, and put the day `25` after the month. \n",
    "\n",
    "This explains why the first record `22-Jan-22 4:08PM` happened to be parsed correctly, as the year and day of month were exactly the same. \n",
    "\n",
    "To handle this, we will need to do explicit conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0327e7",
   "metadata": {},
   "source": [
    "## Explicit Datetime Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87a11a",
   "metadata": {},
   "source": [
    "Study the datetime formatting conventions for Python here. \n",
    "\n",
    "https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "\n",
    "`strftime()` and `strptime()` are used to write a datetime to a formatting string, and parse a datetime from a formatted string respectively. The format codes come from the standard C conventions. Here are a few common ones, many of which we will use in this notebook. Refer to the link above to see all format codes. \n",
    "\n",
    "| Symbol | Description             | Parse Example: 2021-01-13 2:34PM |\n",
    "|--------|-------------------------|----------------------------------|\n",
    "| `%y`     | 2-digit year            | 21                               |\n",
    "| `%m`     | 2-digit month           | 01                               |\n",
    "| `%d`     | 2-digit day of month    | 13                               |\n",
    "| `%b`     | 3-letter month          | Jan                              |\n",
    "| `%I`     | Hour for 12-hour clock  | 2                                |\n",
    "| `%H`     | Hour for 24-hour clock  | 14                               |\n",
    "| `%M`     | 2-digit minute          | 34                               |\n",
    "| `%p`     | AM/PM for 12-hour clock | PM                               |\n",
    "| `%S`     | 2-digit seconds         | 00                               |\n",
    "| `%f`     | Microseconds            | 000000                           |\n",
    "| `%a`     | 3-letter weekday        | Wed                              |\n",
    "| `%A`     | Full name weekday       | Wednesday                        |\n",
    "\n",
    "For our problmatic `ORDER_DATE_TM2` column, we need `%y` to get a two-digit year, a `%b` for the three-letter name of the month, and `%d` for the day of month. For the time we use `%I` for the 12-hour clock hour, `%M` for the minute, and `%p` for the `AM/PM`. We will repair the `ORDER_DATE_TM2` parsing by passing it to the `to_datetime()` function along with the `format` parameter, and then assign this back to the parsed dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d18dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed['ORDER_DATE_TM2'] = pd.to_datetime(df['ORDER_DATE_TM2'], format='%y-%b-%d %I:%M %p')\n",
    "df_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731739f",
   "metadata": {},
   "source": [
    "Much better! Now all the dates are working. We can verify this by counting the number of rows where there is only one unique value between `ORDER_DATE_TM1`,`ORDER_DATE_TM2`, and `ORDER_DATE_TM3`. Sure enough, all 1190 rows have exactly one unique datetime value in each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df_parsed.loc[:,['ORDER_DATE_TM1','ORDER_DATE_TM2','ORDER_DATE_TM3']].nunique(axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2b83c",
   "metadata": {},
   "source": [
    "We can do this same verification for the two plain dates columns to make sure they were parsed correctly too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07206db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df_parsed.loc[:,['ORDER_DATE1','ORDER_DATE2']].nunique(axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b711fdcf",
   "metadata": {},
   "source": [
    "## Filtering on Datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bcb3b6",
   "metadata": {},
   "source": [
    "Let's consolidate our dataframe and rename the columns to just `ORDER_DATE` and `ORDER_DATE_TM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a748925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_parsed[['RECORD_ID','ORDER_DATE1','ORDER_DATE_TM1']] \\\n",
    "    .rename(columns={\"ORDER_DATE1\": \"ORDER_DATE\", \"ORDER_DATE_TM1\": \"ORDER_DATE_TM\"})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc8c8c",
   "metadata": {},
   "source": [
    "Let's say we wanted to get all records where the day of week is Tuesday. In the `dt.dayofweek` property, `0` is going to be Monday and `7` is going to be Sunday. Numerically, this will make Tuesday be a `1`. We can specify this as a condtion and return all records that fall on Tuesday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35cdb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "condition = df['ORDER_DATE'].dt.dayofweek == 1\n",
    "df[condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555b6b2",
   "metadata": {},
   "source": [
    "You can also quickly filter dates and times using a string format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ORDER_DATE'] >= '2022-06-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcd8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[('2022-06-01 12:35PM' <= df['ORDER_DATE_TM']) & (df['ORDER_DATE_TM'] <= '2022-06-05 8:05PM')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a39b3",
   "metadata": {},
   "source": [
    "You can also do more explicit datetime conversions for the start and end bounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bdaf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.to_datetime('2022-06-01 12:35PM', format='%Y-%m-%d %I:%M%p')\n",
    "end = pd.to_datetime('2022-06-05 8:05PM', format='%Y-%m-%d %I:%M%p')\n",
    "\n",
    "df[(start <= df['ORDER_DATE_TM']) & (df['ORDER_DATE_TM'] <= end)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f75e0c",
   "metadata": {},
   "source": [
    "## Dealing with Timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782be0a",
   "metadata": {},
   "source": [
    "Likely one of the biggest headaches you can encounter in data cleaning when it comes to dates and times is timezone conversions. It is ideal if datetimes are stored in **coordinated universal times or UTC**, which is an internationally agreed standard for storing datetimes. If times need to be converted locally, then **offsets** are used to express that local time based off the UTC time. This sounds easier than it actually is, because regional laws around the world evolve and change offsets especially due to daylight savings time. \n",
    "\n",
    "Thankfully there is a convenient library called `pytz` that Pandas already depends on. It will take care of timezone offsets as well as daylight savings time, even capturing DST laws changed in the past! Let's import it and look at the common timezones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "\n",
    "pytz.common_timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a3bb5",
   "metadata": {},
   "source": [
    "Whoa! That's a lot. Let's say we want to localize to Arizona time in the United States. Arizona is kind of special because it does not recognize daylight savings time like the rest of the United States. It gets enough sunlight year round! \n",
    "\n",
    "We will look it up by name and save it to a variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz = pytz.timezone('US/Arizona')\n",
    "tz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46bb13b",
   "metadata": {},
   "source": [
    "Now let's look at our `ORDER_DATE_TM` column in our dataframe. Notice that there is no information about the timezone, making it **timezone naive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b6e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['ORDER_DATE_TM'].dt.tz is None:\n",
    "    print(\"TZ NAIVE\")\n",
    "else:\n",
    "    df['ORDER_DATE_TM'].dt.tz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c11564",
   "metadata": {},
   "source": [
    "Let's say these dates were actually recorded in Arizona local time. We can make `ORDER_DATE_TM` timezone-aware by calling the `tz_localize()` function and specifying they were recorded in `US/Arizona` time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ac26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORDER_DATE_TM'] = df['ORDER_DATE_TM'].dt.tz_localize('US/Arizona')\n",
    "df['ORDER_DATE_TM']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241f4f5",
   "metadata": {},
   "source": [
    "Notice how the datatype of `ORDER_DATE_TM` changes to `datetime64[ns, US/Arizona]`, making it no longer timezone naive and now associated with Arizona time. The `-07:00` part of the value indicates the offset from UTC. \n",
    "\n",
    "We are now free to convert it to different timezones. Let's say we wanted to add an additional column `ORDER_DATE_TM_CST` showing the datetime in US/Central time. We can use `tz_convert` to perform this conversion. Notice below how central time is sometimes 2 hours ahead of Arizona, but also sometimes 1 hour ahead. This is because Arizona does not observe daylight savings time but central time does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ef324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORDER_DATE_TM_CST'] = df['ORDER_DATE_TM'].dt.tz_convert('US/Central')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee4a4a",
   "metadata": {},
   "source": [
    "Finally, we can of course convert the date to `UTC` which we will save to a column `ORDER_DATE_TM_UTC`. Notice the `+00:00` offset as UTC is the baseline with no offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORDER_DATE_TM_UTC'] = df['ORDER_DATE_TM'].dt.tz_convert('UTC')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e766b8b",
   "metadata": {},
   "source": [
    "Isn't it nice how much work the `tz` library did for you? It is encouraged to use it as it will maintain that complex database of timezones, offsets, daylight savings, and historical changes to daylight savings laws for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7802a7",
   "metadata": {},
   "source": [
    "## EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d1cfd2",
   "metadata": {},
   "source": [
    "A dataframe of two columns and two records is shown below. Complete the code below by replacing the question marks `?` so that `ORDER_DATE_TM` is localized to `US/Pacific`. Then add a new column `ORDER_DATE_TM_PARIS` that shows the equivalent time in `Europe/Paris`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0599309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"ORDER_ID\": [1, 2], \n",
    "    \"ORDER_DATE_TM\": [pd.to_datetime('2023-01-05 7:05 PM'), pd.to_datetime('2023-01-06 8:15 AM')]\n",
    "})\n",
    "\n",
    "# localize to US/Pacific\n",
    "df[\"ORDER_DATE_TM\"] = df[\"ORDER_DATE_TM\"].?\n",
    "\n",
    "# convert to Europe/Paris \n",
    "df[\"ORDER_DATE_TM_PARIS\"] = ?\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39255aad",
   "metadata": {},
   "source": [
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"ORDER_ID\": [1, 2], \n",
    "    \"ORDER_DATE_TM\": [pd.to_datetime('2023-01-05 7:05 PM'), pd.to_datetime('2023-01-06 8:15 AM')]\n",
    "})\n",
    "\n",
    "# localize to US/Pacific\n",
    "df[\"ORDER_DATE_TM\"] = df[\"ORDER_DATE_TM\"].dt.tz_localize('US/Pacific')\n",
    "\n",
    "# convert to Europe/Paris \n",
    "df[\"ORDER_DATE_TM_PARIS\"] = df[\"ORDER_DATE_TM\"].dt.tz_convert('Europe/Paris')\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
