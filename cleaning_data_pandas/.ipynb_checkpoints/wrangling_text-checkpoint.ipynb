{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b0a020",
   "metadata": {},
   "source": [
    "# Wrangling Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d460bfd",
   "metadata": {},
   "source": [
    "When you think of data cleaning, one task that probably comes to mind is wrangling text. After all, when people enter data on a form or different formatting conventions are appended together, you will likely find yourself standardizing the data and trying to make it consistent. You will also seek values that were lost in translation and are unusable. \n",
    "\n",
    "In this section we will cover a variety of techniques to wrangle text and perform tasks like finding, replacing, and splitting values. Along the way, we will learn some regular expressions to perform pattern recognition in these tasks. \n",
    "\n",
    "First let's bring in our dependencies, and look at this dataset from Github. Notice how we have some contact information as well as a log of IP address of different users. We are going to learn how to perform some common text operations to clean this dataset and enforce some consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac072dd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "url = 'https://raw.githubusercontent.com/thomasnield/machine-learning-demo-data/master/unprocessed/contacts.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c94d63",
   "metadata": {},
   "source": [
    "These are the common string operations in Pandas we can use. Note that these typically accept a regular expression as a pattern, and we will cover this. \n",
    "\n",
    "| Function   | Description                                                                 |\n",
    "|------------|-----------------------------------------------------------------------------|\n",
    "| `count()`    | Counts the number of instances in a pattern                                 |\n",
    "| `contains()` | Returns a boolean True/False indicating whether a string contains a pattern |\n",
    "| `replace()`  | Replaces the found patterns in a string with another specified string.      |\n",
    "| `fullmatch()`    | Determines if the entire string matches the pattern                         |\n",
    "| `split()`    | Splits a string into separate strings using the pattern as the separator    |\n",
    "| `extract()`  | Finds all occurrences of a pattern and packages them into columns           |\n",
    "| `findall()`  | Finds all occurrences of a pattern and packages them into a list            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e3a21",
   "metadata": {},
   "source": [
    "But first, we will need to cover a few basics with regular expressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910cac3",
   "metadata": {},
   "source": [
    "## Regular Expression Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9d6cd",
   "metadata": {},
   "source": [
    "If you ever have used wildcards to search for text patterns, regular expressions are similar. **Regular expressions** are a special programming language specifically for matching complex text patterns. They allow matching, splitting, and replacing text based on a standardized pattern syntax. You can find them implemented in hundreds of platforms including Python, Java, and SQL. Even IDE's and text editors will allow you to search text using regular expressions such as VSCode, PyCharm, and Notepad++. They are so useful that Pandas makes them the default pattern convention for many of its aforementioned string methods. \n",
    "\n",
    "We are going to learn just enough about regular expressions to get through this notebook.\n",
    "\n",
    "> You can refer to Python's documentation on the `re` package here: https://docs.python.org/3/library/re.html. For a more thorough walkthrough on regular expressions, check out my article with O'Reilly: https://www.oreilly.com/content/an-introduction-to-regular-expressions/\n",
    "\n",
    "Let's first just use plain Python's `re` library which implements regular expressions. We are going to test our regular expressions with the `fullmatch()` function, and wrap it up in a function called `regex_match()` that will simply print whether the pattern matches the string. It will also do some convenient font color formatting in the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def red(str): \n",
    "    return '\\033[91m' + str + '\\033[0m'\n",
    "\n",
    "def green(str): \n",
    "    return '\\033[92m' + str + '\\033[0m'\n",
    "\n",
    "def regex_match(string, pattern):\n",
    "    result = re.fullmatch(pattern=pattern, string=string)\n",
    "\n",
    "    if result:\n",
    "        print(f\"{green(string)} Matches {green(pattern)}\")\n",
    "    else:\n",
    "        print(f\"{red(string)} Doesn't Match {red(pattern)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ffbf6",
   "metadata": {},
   "source": [
    "To match a single uppercase alphabetic character, use the character range `[A-Z]` as a placeholder for a single character. Note how it is case senstive and you can also define arbitrary ranges of letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"C\", \"[A-Z]\") # Match\n",
    "regex_match(\"F\", \"[A-C]\") # Doesn't Match\n",
    "regex_match(\"3\", \"[A-Z]\") # Doesn't Match \n",
    "regex_match(\"c\", \"[A-Z]\") # Doesn't Match \n",
    "regex_match(\"-\", \"[A-Z]\") # Doesn't Match "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbc918",
   "metadata": {},
   "source": [
    "To match both uppercase and lowercase letters, use `[A-Za-z]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ad911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regex_match(\"C\", \"[A-ZA-z]\") # Match\n",
    "regex_match(\"c\", \"[A-Za-z]\") # Matches\n",
    "regex_match(\"3\", \"[A-Za-z]\") # Doesn't Match "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e02ab81",
   "metadata": {},
   "source": [
    "We can also use `[0-9]` to specify a valid digit 0-9, or any arbitrary range of a single digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"9\", \"[0-9]\") # Match\n",
    "regex_match(\"c\", \"[A-Za-z0-9]\") # Match\n",
    "regex_match(\"9\", \"[3-6]\") # Doesn't Match\n",
    "regex_match(\"C\", \"[0-9]\") # Doesn't Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c44e2",
   "metadata": {},
   "source": [
    "You can also specify a set of letters, digits and characters. Below we only qualify the characters A, C, F, 2, 8, or 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d935f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"9\", \"[ACF289]\") # Match\n",
    "regex_match(\"C\", \"[ACF289]\") # Match\n",
    "regex_match(\"7\", \"[ACF289]\") # Doesn't Match\n",
    "regex_match(\"G\", \"[ACF289]\") # Doesn't Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af6022",
   "metadata": {},
   "source": [
    "Letters and digits outside a character range `[ ]` are literally treated as letters and digits in regular expressions. They will match only those values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"Texas\", \"Texas\") # Match\n",
    "regex_match(\"Texas\", \"Arizona\") # Doesn't Match \n",
    "regex_match(\"Texas\", \"TEXAS\") # Doesn't Match "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbde604",
   "metadata": {},
   "source": [
    "If you want to match 3 uppercase alphabetic letters, either write `[A-Z]` three times or put `{3}` repetitions next to the character range.  You can also use `{2,3}` to specify a minimum of 2 repetitions and a maximum of `3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"AEH\", \"[A-Z][A-Z][A-Z]\") # Match\n",
    "regex_match(\"AFH\", \"[A-Z]{3}\") # Match\n",
    "regex_match(\"AFH\", \"[A-Z]{2,3}\") # Match\n",
    "regex_match(\"AF\", \"[A-Z]{2,3}\") # Match\n",
    "regex_match(\"A9H\", \"[A-Z]{2,3}\") # Doesn't Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8135bf",
   "metadata": {},
   "source": [
    "If you want to match one or more instances of a pattern, put a `+` next to it. For example, `[A-Z]+` will match 1 or more alphabetic uppercase characters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d97f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"AEH\", \"[A-Z]+\") # Match\n",
    "regex_match(\"AEHSDHHHNHEHHBV\", \"[A-Z]+\") # Match\n",
    "regex_match(\"93572\", \"[0-9]+\") # Match\n",
    "regex_match(\"AEHSDHHHNHEHHBV\", \"[A-Z0-9]+\") # Match\n",
    "regex_match(\"93572\", \"[A-Z]+\") # Doesn't Match\n",
    "regex_match(\"AEHSDHHHNHEHHBV\", \"[0-9]+\") # Doesn't Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ae91d",
   "metadata": {},
   "source": [
    "Another helpful quantifier is the `?` which matchs 0 or 1 instances of a pattern. For example, we can use it to specify an optional digit in front of two uppercase letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c95639",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"2GH\", \"[0-9]?[A-Z]{2}\") # Match\n",
    "regex_match(\"GH\", \"[0-9]?[A-Z]{2}\") # Match\n",
    "regex_match(\"2H\", \"[0-9]?[A-Z]{2}\") # No Match\n",
    "regex_match(\"22H\", \"[0-9]?[A-Z]{2}\") # No Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6accc24",
   "metadata": {},
   "source": [
    "The dot `.` represents a wildcard character, matching any single character including non-alphanumeric characters like punctuation and symbols. If you intend to match a literal dot, use an escape slash in front of it `\\.`. \n",
    "\n",
    "With a wildcard character, you can also put a quantifier like `{3}` or `+` after it to specify 3 characters or one or more characters respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babcbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"A#H\", \"...\") # Match\n",
    "regex_match(\"A#H\", \".{3}\") # Match \n",
    "regex_match(\"A#H\", \".+\") # Match\n",
    "regex_match(\"AH\", \".{3}\") # Doesn't Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e061210",
   "metadata": {},
   "source": [
    "Finally, the last operator we need to know is grouping up parantheses `()` as well as the alternator `|`. If I want to only match airport connections from `ABQ` or `DAL` to `HOU` or `PHX`, I could express that with `(ABQ|DAL)-(HOU|PHX)`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7177933",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"ABQ\", \"(ABQ|DAL)\") # Match \n",
    "regex_match(\"ABQ-HOU\", \"(ABQ|DAL)-(HOU|PHX)\") # Match \n",
    "regex_match(\"DAL-HOU\", \"(ABQ|DAL)-(HOU|PHX)\") # Match \n",
    "regex_match(\"DAL-PHX\", \"(ABQ|DAL)-(HOU|PHX)\") # Match \n",
    "regex_match(\"PHX-DAL\", \"(ABQ|DAL)-(HOU|PHX)\") # Doesn't Match \n",
    "regex_match(\"MDW-DAL\", \"(ABQ|DAL)-(HOU|PHX)\") # Doesn't Match \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1525cb9",
   "metadata": {},
   "source": [
    "## Partial String Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24cf3e",
   "metadata": {},
   "source": [
    "Let's say we want to find all records with an `Email` containing a domain of `outlook.com`. This is easy enough using the `contains()` function under the `str` property. Note that the pattern string is treated as a regular expression so we need to escape the dot `.` with a backslash `\\.`. Otherwise, it will be treated as a wildcard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce026547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Email'].str.contains('outlook\\.com', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f1e87",
   "metadata": {},
   "source": [
    "Since one of the values for email is `NaN`, we will need to handle it if we are to use this as a filtering mask. We can do that by passing `na = False` to the `contains()` function. This will cause missing values to be treated as `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5e5b7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['Email'].str.contains('outlook\\.com', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10f882",
   "metadata": {},
   "source": [
    "## Full String Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe75b7",
   "metadata": {},
   "source": [
    "Let's say we want to hunt down invalid IP addresses. While we can [get wildly specific and elaborate with ipv4 patterns](https://stackoverflow.com/questions/5284147/validating-ipv4-addresses-with-regexp) let's keep it simple. \n",
    "\n",
    "Below is a simplistic regular exression to match an IP address. We use the `fullmatch()` to qualify the IP address string in full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbed4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipAddressRegex = r'[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}'\n",
    "\n",
    "df['IP_ADDRESS'].str.fullmatch(ipAddressRegex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7214e",
   "metadata": {},
   "source": [
    "> Typically, you only need to make your regular expression as specific enough to capture what you're looking for in the data. If you do not know your data well, you will want to err on being more specific. \n",
    "\n",
    "Let's use to qualify IP addresses that don't match in a condition. Sure enough, we have one broken IP address that exceeds 4 digits between the `.` separators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa566e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df['IP_ADDRESS'].str.fullmatch(ipAddressRegex) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9914f60b",
   "metadata": {},
   "source": [
    "Here's another example finding invalid US phone numbers. Note how we qualify the first 3 digits, then the next 3, and then then final 4 digits. Variants that may or may not contain hypens `-`, parantheses for area code `( )`, and spaces. Sure enough we find three broken phone numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57a3fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['Phone'].str.fullmatch(r\"\\(?[0-9]{3}\\)?[ -]?[0-9]{3}[ -]?[0-9]{4}\") == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54210dcc",
   "metadata": {},
   "source": [
    "Let's go ahead and only include rows in our dataframe that have valid phone numbers and IP addresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f275e1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df[df['Phone'].str.fullmatch(r\"\\(?[0-9]{3}\\)?[ -]?[0-9]{3}[ -]?[0-9]{4}\")]\n",
    "\n",
    "df = df[df['IP_ADDRESS'].str.fullmatch(ipAddressRegex)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a2162",
   "metadata": {},
   "source": [
    "Finally, let's identify all invalid email addresses. An email needs to have a series of alphanumeric characters (with some allowable symbols like dot `.`), followed by the `@` symbol, then the domain. We will also treat `na` as false to also capture missing email addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7db943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Email'].str.fullmatch(r'[.A-Za-z0-9]+@[A-Za-z0-9]+\\.[A-Za-z]+', na=False) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ab3c9",
   "metadata": {},
   "source": [
    "So we find two email addresses that are missing or broken. Lily's email is missing a domain! We will remove those two instances from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c51638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Email'].str.fullmatch(r'[.A-Za-z0-9]+@[A-Za-z0-9]+\\.[A-Za-z]+', na=False)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04736781",
   "metadata": {},
   "source": [
    "## Finding All Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946b8c8",
   "metadata": {},
   "source": [
    "We can also use `findall()` to look for all partial matches of a regular expression and return them as a series. Below we extract all the email domains from the `Email` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Email'].str.findall(r'[A-Za-z0-9]+\\.[A-Za-z]{3}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47f27f",
   "metadata": {},
   "source": [
    "If we wanted to gather the unique domains, we can join the \"lists\" of single items into a string and then qualify the unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Email'].str.findall(r'[A-Za-z0-9]+\\.[A-Za-z]{3}$').str.join(\"\").unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4cd34",
   "metadata": {},
   "source": [
    "## Replacing Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f783bd2",
   "metadata": {},
   "source": [
    "Let's say we want to clean up phone numbers by removing any extraneous dashes `-`, parantheses `()`, and spaces ` `. We can do that by using a regular expression character set `[- ()]`. Note we have to make the dash `-` the first character so it doesn't get confused as a range operator. We also throw a space ` ` in there too so we capture spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Phone'].str.replace(r\"[- ()]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b5db23",
   "metadata": {},
   "source": [
    "## Splitting Text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be2f72",
   "metadata": {},
   "source": [
    "A powerful tool we can use to split text into columns is use the `str.split()` function. We provide a pattern that can be a separator (like commas `,`) or a full-on regular expression pattern. \n",
    "\n",
    "Here is how we can separate out the email domains into separate columns. We can then rename these columns and append them back to our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e25d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Email'].str.split(\"@\", expand=True, regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8a159",
   "metadata": {},
   "source": [
    "When you use regular expression features like look-aheads, it opens up more powerful splitting capabilities based on surrounding characters. This is beyond the scope of this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a386c",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e2243",
   "metadata": {},
   "source": [
    "Complete the code below by replacing the question mark `?`. Replace it with a regular expression operation to identify records that are missing a street number in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb10b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"CUSTOMER_NAME\" : [\"Rex Tooling\", \"Prairie Construction\", \"Banke Logistics\"],\n",
    "    \"STREET_ADDRESS\" : [\"147 Collie Way\", \"56 Samson Dr\", \"Elijah Blvd\"]\n",
    "})\n",
    "\n",
    "df[? == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b43f03",
   "metadata": {},
   "source": [
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4195dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"CUSTOMER_NAME\" : [\"Rex Tooling\", \"Prairie Construction\", \"Banke Logistics\"],\n",
    "    \"STREET_ADDRESS\" : [\"147 Collie Way\", \"56 Samson Dr\", \"Elijah Blvd\"]\n",
    "})\n",
    "\n",
    "df[df[\"STREET_ADDRESS\"].str.fullmatch(\"[0-9]+ [A-Za-z0-9]+ (Way|Blvd|Dr|St)\") == False]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
