{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0584ebd",
   "metadata": {},
   "source": [
    "# Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b13b00",
   "metadata": {},
   "source": [
    "Why can a dataset have missing values? Sometimes an observation could not be recorded for whatever reason, like a sensor or instrument being broken or a survey respondent chose to not answer a question. Unfortunately, machine learning and statistical models often do not cope well with missing values. For this reason you will likely consider removing them. \n",
    "\n",
    "In this section, we will cover how to identify and remove data related to missing values.\n",
    "\n",
    "> Please be advised you should fully understand why values are missing and trace back to the source of what produced the data. You should also be mindful of any selection biases that might emerge because of the missing data. For example, if you remove survey respondent records that did not answer a certain question... that can bias your models towards the population that chose to answer! Sometimes it is more interesting to ask why values are missing than just ignoring them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7ea7b",
   "metadata": {},
   "source": [
    "To get setup, let's bring in a SQLite database and extract the data from the `WEATHER_MONITOR` table. However, we will only analyze on region of stations by getting only records with `LOCATION_ID` of `2`,`28`, or `48`, and for the month of April. We will have SQL do that filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a553272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "# Download SQLite database and connect to it \n",
    "urllib.request.urlretrieve(\"https://github.com/thomasnield/machine-learning-demo-data/blob/master/relational/company_operations.db?raw=true\", \"company_operations.db\") \n",
    "\n",
    "conn = sqlite3.connect('company_operations.db')\n",
    "\n",
    "df = pd.read_sql(\"\"\"\n",
    "SELECT * FROM WEATHER_MONITOR \n",
    "WHERE LOCATION_ID IN (2,28,48) \n",
    "AND strftime('%m', REPORT_DATE) = '04'\n",
    "\n",
    "\"\"\", conn, parse_dates=['REPORT_DATE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b509c4",
   "metadata": {},
   "source": [
    "> If you want to learn more about SQL, check out the [Anaconda course here](https://learning.anaconda.cloud/introduction-to-sql).\n",
    "\n",
    "Notice above that the `RAIN` column has `NaN` values, meaing those values are `None` and missing. There is also one record where a `TEMPERATURE` value is mssing. We are going to learn a few techniques on how to identify and handle these. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab303180",
   "metadata": {},
   "source": [
    "## Tracking Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44af0d",
   "metadata": {},
   "source": [
    "To find missing values, we can use the `isna()` function on a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614acc88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ef9ac",
   "metadata": {},
   "source": [
    "We can also use the `any()` function to see which columns contain any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1da5a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f60e7",
   "metadata": {},
   "source": [
    "You can also flip the axis for `any()` and get a boolean series of whether each row contains a missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04206eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f3cc04",
   "metadata": {},
   "source": [
    "Note there is also a `notna()` counterpart which will flip the condition and set provided values to `True` and missing values to `False`. There are also aliases `isnull()` and `notnull()` which are just different names for the same operations.\n",
    "\n",
    "Of course, we can take that boolean series and pass it to the `loc` getter to retrieve those columns with `NaN` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ad0a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, df.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8feeb",
   "metadata": {},
   "source": [
    "To find missing values for specific columns, we can use a filtering operation using logical operators. Here we find all records where there was a missing `TEMPERATURE` or `RAIN` value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3281919",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df['TEMPERATURE'].isna() | df['RAIN'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c6bb7",
   "metadata": {},
   "source": [
    "We can also filter for all records containing any missing values across all fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3790046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae891dd5",
   "metadata": {},
   "source": [
    "## Removing Rows with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0da8f",
   "metadata": {},
   "source": [
    "As stated earlier, many machine learning and statistical models do not tolerate `NA`, `NaN`, or other missing null values. If you understand why they are missing, and do not think their absence will bias your model significantly, then you can simply remove those records with missing values. \n",
    "\n",
    "You can use the `drop()` operator with conditional logic as we learned in previous sections, but there is also a handy `dropna()` function just for this purpose. \n",
    "\n",
    "Below we use `dropna()` to remove all records with `NaN` values. Note I am not using the `inplace=True` parameter here so I can demonstrate other examples later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0) # use inplace=True to replace current dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef58279",
   "metadata": {},
   "source": [
    "Notice those four records with `NaN` values for `RAIN` or `TEMPERATURE` are now gone. We can also provide only a `subset` of indices to consider for dropping null values. Below, we only drop records where `NA` exists in the `RAIN` column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5859880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, subset=[\"RAIN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6994d42",
   "metadata": {},
   "source": [
    "If we would rather drop those columns with `NaN` values instead, we can use `axis=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa0b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d68a0c",
   "metadata": {},
   "source": [
    "## Replacing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f878ce",
   "metadata": {},
   "source": [
    "While this may not make sense from a machine learning perspective, there may be times you want to replace missing values. You can do this by using teh `fillna()` function. Below we replace all `na` values in our table with `-1`. Unfortunately, there is no `subset` paramter for this function so to target specific columns you will need to extract them out, apply the `fillna()` function, and then assign them back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded8d13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.fillna(value=-1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512c1bd",
   "metadata": {},
   "source": [
    "> There are other methods that `fillna()` can do to fill in missing values. [Be sure to read the Pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna) to learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68830148",
   "metadata": {},
   "source": [
    "Conversely there may be times you want to replace certain values with `na`, such as empty strings or placeholder strings like 'NULL'. We just turned the `NaN` values into `-1`. Let's convert them back to `NaN` using the `replace()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c63cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "\n",
    "df.replace(-1, nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122a73f",
   "metadata": {},
   "source": [
    "## Fill in Missing Values with Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae0e1d",
   "metadata": {},
   "source": [
    "Another way to cope with missing values that might be more agreeable for machine learning and statistical models is to use a statistical value replacement such as a `mean` or `median`. \n",
    "\n",
    "Let's bring in the `SimpleImputer` from scikit-learn and set it to use the `mean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29985c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb62a7c4",
   "metadata": {},
   "source": [
    "Let's then apply the `TEMPERATURE` and `RAIN` fields to the imputer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_input = df[['TEMPERATURE','RAIN']]\n",
    "\n",
    "imputer.fit(transform_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67298c8",
   "metadata": {},
   "source": [
    "The `SimpleImputer` will calculate the mean for `RAIN` to be `0.8585` and for `TEMPERATURE` to be `59.740909`. We can then apply these columns with the means replacing the `NaN`'s to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the weather dataframe \n",
    "mean_df = df.copy() \n",
    "\n",
    "# apply mean to the TEMPERATURE and RAIN column\n",
    "transform_output = imputer.transform(transform_input)\n",
    "mean_df[['TEMPERATURE','RAIN']] = transform_output\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88718322",
   "metadata": {},
   "source": [
    "Note there are other options for the `strategy` parameter including 'mean', 'median', 'most_frequent', and 'constant'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38ab9e",
   "metadata": {},
   "source": [
    "## Fill in Missing Values with Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835660a7",
   "metadata": {},
   "source": [
    "Another option for imputing a value to replace missing values is to leverage k-nearest neighbor (KNN), which works quite well in many cases. Essentially, the idea is to find datapoints that are close to the one with the missing value, all fields considered. Those neighboring records are then used to infer an estimate for the missing value. \n",
    "\n",
    "Let's bring in the `KNNInputer` and use the 5 nearest neighbors. We will make the weights uniform and we will tell it to not ignore `NaN` values by setting `metric` to `nan_euclidean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd4baf",
   "metadata": {},
   "source": [
    "Since we are inferring based on some other fields, we need to kick out `ID`,`LOCATION_ID`, and `REPORT_CODE` as those are not useful for the KNN model. They are arbitrary values or randomly generated and have no predictive value. We also need to convert the `REPORT_DATE` to a numeric value. Thankfully we are only working with one month, so let's just grab the day of month and that will be our numeric conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the datafarme and drop two columns that are not useful for modeling\n",
    "knn_input = df.drop(['ID','REPORT_CODE','LOCATION_ID'],axis=1)\n",
    "\n",
    "# extract day of month and make that the `REPORT_DATE`\n",
    "knn_input['REPORT_DATE'] = knn_input['REPORT_DATE'].dt.strftime('%d').astype(int)\n",
    "\n",
    "# fit the knn model \n",
    "imputer.fit(knn_input)\n",
    "knn_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc44c51",
   "metadata": {},
   "source": [
    "Finally, let's copy the dataframe and apply the transformation to the two columns. The `RAIN` values with row indices of 5, 18, and 19 were missing but now are `0.604`, `0.996`, and `0.986` respectively. The missing `TEMPERATURE` value of row index 12 is inferred to be `55.76`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the dataframe\n",
    "knn_output = df.copy()\n",
    "\n",
    "# apply knn transform to the input\n",
    "knn_transform = imputer.transform(knn_input)\n",
    "\n",
    "# apply only the TEMPERATURE and RAIN columns back to the dataframe\n",
    "knn_output.loc[:,[\"TEMPERATURE\",\"RAIN\"]] = knn_transform[:,[1,3]]\n",
    "knn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3ebae",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5a9465",
   "metadata": {},
   "source": [
    "In the code below is a sample of thermostat data. Complete the code below so the median is imputed for the `temperature` and `humidity` fields' missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692528b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"record_id\" : ['OVUTJE','OVUTJE','WI4QEX','WI4QEX','FS40NF','O64LIT','U888EA'],\n",
    "    \"temperature\" : [65.2, 65.2, None, 57.2, 57.4, None, 27.5], \n",
    "    \"humidity\" : [.8, None, .7, .6, .7, .7, .8]\n",
    "})\n",
    "\n",
    "# create and fit imputer \n",
    "imputer = ?\n",
    "transform_input = df[['temperature','humidity']]\n",
    "imputer.fit(?)\n",
    "\n",
    "# apply mean to the temperature and humidity column\n",
    "transform_output = imputer.transform(?)\n",
    "df[['temperature','humidity']] = transform_output\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a480b06",
   "metadata": {},
   "source": [
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183215e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"record_id\" : ['OVUTJE','OVUTJE','WI4QEX','WI4QEX','FS40NF','O64LIT','U888EA'],\n",
    "    \"temperature\" : [65.2, 65.2, None, 57.2, 57.4, None, 27.5], \n",
    "    \"humidity\" : [.8, None, .7, .6, .7, .7, .8]\n",
    "})\n",
    "\n",
    "# create and fit imputer \n",
    "imputer = SimpleImputer(strategy='median')\n",
    "transform_input = df[['temperature','humidity']]\n",
    "imputer.fit(transform_input)\n",
    "\n",
    "# apply mean to the TEMPERATURE and RAIN column\n",
    "transform_output = imputer.transform(transform_input)\n",
    "df[['temperature','humidity']] = transform_output\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
